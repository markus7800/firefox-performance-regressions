{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.data_utils import *\n",
    "from experiments.plot_utils import *\n",
    "from experiments.hyperparam_tuning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features = get_ml_data_traditional('bugbug', 'performance', 'commitlevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = features.columns\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features(clf, X, feature_names):\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    #explainer = shap.Explainer(clf)\n",
    "\n",
    "    # print(explainer)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    shap.summary_plot(shap_values, X, max_display=10, feature_names=feature_names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf, plot_feature_importance=True):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Train:\")\n",
    "    y_pred = clf.predict(X_train)\n",
    "    report = metrics.classification_report(y_train, y_pred)\n",
    "    print(report)\n",
    "    if plot_feature_importance:\n",
    "        plot_important_features(clf, X_train, feature_names)\n",
    "    #ConfusionMatrixDisplay(confusion_matrix(y_train, y_pred), display_labels=['no regr.', 'regr.']).plot()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Test:\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    #plot_important_features(clf, X_test, feature_names)\n",
    "    plot_precision_recall_curve_with_f1(clf, X_test, y_test)\n",
    "\n",
    "    #ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=['no regr.', 'regr.']).plot()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clf():\n",
    "    clf = xgboost.XGBClassifier(\n",
    "        n_jobs=4,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "        )\n",
    "    return clf\n",
    "\n",
    "# def make_clf():\n",
    "#     from sklearn.linear_model import LogisticRegression\n",
    "#     clf = LogisticRegression()\n",
    "#     return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=True)\n",
    "clf = make_clf()\n",
    "ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=False)\n",
    "clf = make_clf()    \n",
    "ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference not as pronounced with Logistic Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=True)\n",
    "clf = default_pipeline()\n",
    "clf.set_params(model=LogisticRegression(random_state=0, C=2), sampler=RandomOverSampler(random_state=0))\n",
    "\n",
    "ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf, plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = pd.read_csv('data/labeling/bugbug.csv')\n",
    "labeling['index'] = labeling['revision']\n",
    "labeling.set_index('index', inplace=True)\n",
    "labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_ids = set(labeling['bug_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_id_counts = (labeling\n",
    "    .loc[labeling['performance']==1, ['revision', 'bug_id']]\n",
    "    .groupby('bug_id').count()\n",
    "    .sort_values('revision'))\n",
    "\n",
    "bug_id_counts.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many performance bug have single commit vs multiple commits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_commit_bug_ids = set(bug_id_counts[bug_id_counts['revision'] == 1].index)\n",
    "multi_commit_bug_ids = set(bug_id_counts[bug_id_counts['revision'] > 1].index)\n",
    "\n",
    "total = len(single_commit_bug_ids) + len(multi_commit_bug_ids)\n",
    "print(f\"#single = {len(single_commit_bug_ids)}, #multiple = {len(multi_commit_bug_ids)}, total = {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And how many commits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_commit_bug_commits = labeling.loc[labeling['bug_id'].isin(single_commit_bug_ids), 'revision']\n",
    "multi_commit_bug_commits = labeling.loc[labeling['bug_id'].isin(multi_commit_bug_ids), 'revision']\n",
    "\n",
    "total = len(single_commit_bug_commits) + len(multi_commit_bug_commits)\n",
    "print(f\"#single = {len(single_commit_bug_commits)}, #multiple = {len(multi_commit_bug_commits)}, total = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.repo_miner import get_commit_log\n",
    "commit_log = get_commit_log('data/repo_miner/commit_log.csv')\n",
    "commits = commit_log.drop('revision', axis=1).join(labeling, how='inner')\n",
    "commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_id = 1700052\n",
    "commits[commits['bug_id'] == bug_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['id'] = commits['id']\n",
    "df = features.loc[\n",
    "    commits['bug_id'] == bug_id,\n",
    "    [\n",
    "        'id',\n",
    "        'developer_age',\n",
    "        'recent_developer_experience',\n",
    "        'recent_backouts_developer'\n",
    "    ]\n",
    "].iloc[:5]\n",
    "df.index.name = 'revision hash'\n",
    "df.columns = ['Commit Id', 'Developer Seniority', 'Recent Developer Experience', 'Recent Backouts Developer']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does XGBoost learn proxy for revision id?\n",
    "\n",
    "### Does it just memorize the position of the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take id\n",
    "y = np.array(commits['performance'], 'int')\n",
    "\n",
    "X = commits[['id']]\n",
    "\n",
    "feature_names = X.columns\n",
    "X = np.array(X)\n",
    "print(f'{X.shape=}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=True)\n",
    "clf = make_clf()  \n",
    "ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=False)\n",
    "clf = make_clf()\n",
    "ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labeling = pd.read_csv('data/labeling/bugbug.csv')\n",
    "labeling.set_index('revision', inplace=True)\n",
    "\n",
    "for kind in ['commitlevel', 'buglevel']:\n",
    "    target = 'performance'\n",
    "\n",
    "    features = pd.read_csv(f'data/feature_extractor/features_{kind}.csv')\n",
    "\n",
    "    if kind == 'buglevel':\n",
    "        # labeling is based on bugnumber, that's why it is ok to index at\n",
    "        # first revision of a commit group in case of kind=='buglevel'\n",
    "        features['revision'] = features['first_revision']\n",
    "        features['id'] = features['first_id']\n",
    "\n",
    "    features.set_index('revision', inplace=True)\n",
    "\n",
    "\n",
    "    features['target'] = labeling[target] # works because index is revision hash\n",
    "\n",
    "    subset = features[(483000 <= features['id']) & (features['id'] <= 485000)]\n",
    "\n",
    "    plt.figure(figsize=(24, 4))\n",
    "    plt.scatter(\n",
    "        subset.loc[subset['target'] == 1, 'id'], \n",
    "        np.full((subset['target'] == 1).sum(), 1),\n",
    "        s=1)\n",
    "    plt.title(kind)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now compare to buglevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features = get_ml_data_traditional('bugbug', 'performance', 'buglevel')\n",
    "feature_names = features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=True)\n",
    "clf = make_clf()       \n",
    "ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, shuffle=False)\n",
    "clf = make_clf()       \n",
    "ml_pipeline(X_train, X_test, y_train, y_test, feature_names, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4696bc64be58b0e5e207e22dca014ef47cd404c337c3ddfbdfdc381921ec8122"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
